import sys, os, ray, torch, numpy as np, glob
sys.path.append("/kaggle/working")
from ray.rllib.algorithms.ppo import PPOConfig
from ray.rllib.models import ModelCatalog
from ray.tune.registry import register_env
from train.multi_agent_env import raw_env
from train.gnn_model import GNNTrafficModel
from ray.rllib.env.wrappers.pettingzoo_env import ParallelPettingZooEnv

# 1. KayÄ±t Ä°ÅŸlemleri
ModelCatalog.register_custom_model("gnn_traffic_model", GNNTrafficModel)

def env_creator(config):
    return ParallelPettingZooEnv(raw_env(
        sumo_cfg_path="/kaggle/working/maltepe.sumocfg",
        max_steps=10000, 
        label="kaggle_mega_hybrid_v4"
    ))

register_env("multi_agent_traffic_v4", lambda config: env_creator(config))

# 2. Ray BaÅŸlatma
ray.shutdown()
ray.init(ignore_reinit_error=True, num_cpus=4)

# 3. PPO KonfigÃ¼rasyonu
config = (
    PPOConfig()
    .environment("multi_agent_traffic_v4")
    .framework("torch")
    .api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)
    .resources(num_gpus=1)
    .env_runners(num_env_runners=1) 
    .training(
        model={"custom_model": "gnn_traffic_model"},
        train_batch_size=4000,
        lr=5e-5,
        gamma=0.99
    )
    .multi_agent(
        policies={"default_policy"},
        policy_mapping_fn=lambda agent_id, *args, **kwargs: "default_policy"
    )
)

print("ğŸš¦ Maltepe Digital Twin: AkÄ±llÄ± KayÄ±t Sistemli Mega Fine-tune BaÅŸlatÄ±lÄ±yor...")
algo = config.build()

# 4. AKILLI RESUME (KaldÄ±ÄŸÄ± Yerden Devam) MANTIÄI
checkpoint_dir = "/kaggle/working/mega_v4_checkpoints"
os.makedirs(checkpoint_dir, exist_ok=True)

# Ã–nce Ã§alÄ±ÅŸma alanÄ±ndaki en gÃ¼ncel checkpoint'e bak
local_checkpoints = sorted(glob.glob(os.path.join(checkpoint_dir, "checkpoint_*")), reverse=True)
base_ckpt = "/kaggle/input/gnn-hybrid-v4-new/checkpoint_000300"

if local_checkpoints:
    latest_local = local_checkpoints[0]
    print(f"â™»ï¸ Ã‡alÄ±ÅŸma alanÄ±ndan DEVAM EDÄ°LÄ°YOR: {latest_local}")
    algo.restore(latest_local)
elif os.path.exists(base_ckpt):
    print(f"ğŸ“¥ BaÅŸlangÄ±Ã§ aÄŸÄ±rlÄ±klarÄ± yÃ¼kleniyor (Fine-tune): {base_ckpt}")
    algo.restore(base_ckpt)
else:
    print("âš ï¸ UYARI: HiÃ§bir checkpoint bulunamadÄ±, sÄ±fÄ±rdan eÄŸitim baÅŸlÄ±yor!")

# 5. EÄÄ°TÄ°M DÃ–NGÃœSÃœ
print("ğŸ”¥ EÄŸitim AteÅŸlendi. Her 5 iterasyonda bir ve durdurulduÄŸunda otomatik kayÄ±t yapÄ±lacak.")

try:
    for i in range(1, 201): # Toplam 200 iterasyon hedefi
        print(f"ğŸŸ¡ Ä°terasyon {i} baÅŸlatÄ±ldÄ± (SimÃ¼lasyon akÄ±yor... LÃ¼tfen bekleyin)")
        result = algo.train()
        
        reward = result.get('episode_reward_mean')
        reward_str = f"{reward:.2f}" if reward is not None else "Veri toplanÄ±yor..."
        print(f"ğŸ“ˆ [Kaggle Mega] Ä°terasyon {i} | Ortalama BaÅŸarÄ± (Reward): {reward_str}")
        
        # Her 5 iterasyonda bir otomatik kayÄ±t
        if i % 5 == 0:
            save_path = algo.save(checkpoint_dir=checkpoint_dir)
            print(f"ğŸ’¾ OTOMATÄ°K KAYIT TAMAMLANDI: {save_path}")

except KeyboardInterrupt:
    print("\nğŸ›‘ EÄŸitim kullanÄ±cÄ± tarafÄ±ndan durduruldu! Son durum kaydediliyor...")
except Exception as e:
    print(f"âš ï¸ Kritik bir hata oluÅŸtu: {e}")
finally:
    # Her durumda en son hali kaydet
    final_save = algo.save(checkpoint_dir=checkpoint_dir)
    print(f"âœ… NÄ°HAÄ° GÃœVENLÄ°K KAYDI ALINDI: {final_save}")
    ray.shutdown()
