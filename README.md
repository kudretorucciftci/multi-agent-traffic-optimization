# ğŸš¦ Maltepe Digital Twin: Hybrid Multi-Agent Traffic Control

![Simulation Output](assets/simulation.gif)

Bu proje, Ä°stanbul Maltepe bÃ¶lgesinin trafik akÄ±ÅŸÄ±nÄ± **Hybrid Multi-Agent Systems (MAS)** ve **Knowledge Graph** topolojisi kullanarak optimize eden ileri seviye bir **Deep Reinforcement Learning** Ã§Ã¶zÃ¼mÃ¼dÃ¼r.

## ğŸ§  System Architecture & Hybrid MAS

Sistem, ÅŸehir Ã¶lÃ§eÄŸinde bir koordinasyon saÄŸlamak iÃ§in iki farklÄ± **Agent** tipini birleÅŸtiren hibrit bir mimari kullanÄ±r:

1.  **Learning Agents (6 RL Agents):** Ana arterlerdeki trafik Ä±ÅŸÄ±klarÄ±nÄ± (TLS) kontrol eden, **MAPPO (Multi-Agent PPO)** algoritmasÄ± ile eÄŸitilmiÅŸ zekalar.
2.  **Supportive Agents (143 Rule-based Agents):** KavÅŸak giriÅŸlerinde konumlandÄ±rÄ±lan ve **Variable Speed Limit (VSL)** kurallarÄ±yla trafik akÄ±ÅŸÄ±nÄ± Learning Agent'lar iÃ§in stabilize eden yardÄ±mcÄ± birimler.
3.  **Knowledge Graph Topology:** Agent'lar sadece kendi bÃ¶lgelerini deÄŸil, Knowledge Graph Ã¼zerinden tanÄ±mlanan komÅŸuluk iliÅŸkileri sayesinde **Spatial Awareness** (mekansal farkÄ±ndalÄ±k) ile hareket eder. Bir bÃ¶lgedeki yoÄŸunluk, grafik yapÄ±sÄ± Ã¼zerinden diÄŸer agent'lara veri olarak aktarÄ±lÄ±r.

## ğŸš€ Training & Fine-tuning Process

Modelin baÅŸarÄ±sÄ±, aÅŸamalÄ± bir eÄŸitim stratejisiyle (Curriculum Learning benzeri) elde edilmiÅŸtir:

-   **Base Training (500 Iterations):** 6 ana agent iÃ§in temel trafik yÃ¶netim politikalarÄ± ve Knowledge Graph entegrasyonu saÄŸlandÄ±.
-   **Fine-tuning V4 (200 Iterations):** Hibrit yapÄ±nÄ±n (149 Agents) devreye alÄ±nmasÄ±yla, Ã¶dÃ¼l fonksiyonu (Reward Function) kararlÄ±lÄ±ÄŸÄ± Ã¼zerinde ince ayar (Fine-tuning) yapÄ±ldÄ±.
-   **Toplam Ä°lerleme:** BaÅŸlangÄ±Ã§ta **-245.000** seviyesinde olan kÃ¼mÃ¼latif **Reward**, Fine-tuning sonunda **-24.769** bandÄ±na Ã§ekilerek sistem doyuma (Plateau) ulaÅŸtÄ±rÄ±ldÄ±.

## ğŸ“‰ Benchmarking Results

Sistemin baÅŸarÄ±sÄ± 3 farklÄ± senaryoda sayÄ±sal olarak kanÄ±tlanmÄ±ÅŸtÄ±r:

| Metrics | **Static (No AI)** | **6 RL Agents (MLP)** | **Final Hybrid (GNN/VSL)** |
| :--- | :--- | :--- | :--- |
| **System Reward Score** | -245.000 | -182.014 | **-24.769** |
| **Avg. Waiting Time** | 240+ sec | 158 sec | **32 sec** |
| **Throughput (Veh/Hr)** | 450 | 720 | **1.280** |
| **Gridlock Probability** | %95 | %40 | **<%2** |

## ğŸ› ï¸ Commands & Usage

1.  **Install Requirements:**
    ```bash
    pip install -r requirements.txt
    ```
2.  **Run Visual Simulation:**
    ```bash
    python run/run_simulation.py
    ```
3.  **Monitor with Tensorboard:**
    ```bash
    tensorboard --logdir ppo_trafik_isigi_tensorboard
    ```

---
*Developed by: [Kudret OruÃ§ Ã‡iftÃ§i / Multi-Agent Traffic Optimization]*
